# 深度学习基础知识

## BP算法

参考印象笔记《反向传播理解》

![1553858014863](imgs/深度学习/1553858014863.png)

上图为NG讲的BP算法，只不是上图是按照单个实例来计算的，要是按照批量数据的话，$\delta$和梯度的更新为下图。BP算法其实很好记，数据维度来辅助记忆就行。例如L层有两个结点，则$\delta^{L}$为$m\times2$,L+1层有3个结点，则$\delta^{L+1}$为$m\times3$.$\theta_{L}$为$\R^{2\times3}$，下面根据矩阵维度来辅助推导公式就行啦。

![1553858108228](imgs/深度学习/1553858108228.png)

## 优化算法

### 指数加权（移动）平均

**Exponentially Weighted (moving) average** 本质上是一种近似求平均的方法。

![1552901553645](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552901553645.png)

![1553856653926](imgs/深度学习/1553856653926.png)

例如$\theta_{t}$代表第t天的温度，$v_{t}$代表第t天的平均温度。指数加权平均对t个样本以一定权重累积求和而得，其中样本权重以指数衰减方式递减，距离当前数值越远的数值的权重越低，指数加权平均近似于$\frac{1}{1-\beta}$个数值的平均值，其中$\beta$ 系数越大，类似滑动的窗口越大，也就是平滑的效果越强，因为计算平均所用的样本多（或者之前样本的权重较大）。

### 基于动量的优化

基于动量的优化方式使得当前参数更新的方向不仅只看梯度的方向，还考虑到了之前的梯度方向，这儿使得梯度方向更新具有惯性。这儿动量优化使用的技术类似于指数加权平均，分别先计算当前mini batch的梯度$d_{w}$，然后加上之前梯度的指数衰减，用总梯度来更新当前参数。（这儿NG说自己更喜欢在$d_{w}$前面乘$1-\beta$）

![1552901978270](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552901978270.png)

参考：

NG deeplearning

[通俗理解指数加权平均](https://zhuanlan.zhihu.com/p/29895933)

### RMSProp

PMSProp由Hiton提出，体现出环境感知的能力，PMSProp能够自适应调整学习率。同样的我们想要在指向最优解的方向更大的更新力度更大，在非最优梯度方向更新力度小一点,NG这儿是利用w,b两个参数的方向来举例的，我们想要在w方向更新更快点，b方向更小点。为了达成这个目的，PMSProp使用了梯度的平方（二阶矩）信息，同样的基本思想是结合之前的梯度平方信息来平滑当前梯度。不同于动量方法有两点，第一点是PMSProp这儿累积的是梯度平方（二阶矩信息），而动量方法累积的是梯度(一阶矩)信息；第二点是RMSProp能够自适应调整学习率

![1552902425035](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552902425035.png)



### Adam

Adam是基于动量和PMSProp两种优化算法的结合版，Adam通过记录梯度的一阶矩，也就是过往梯度和当前梯度的平均，这体现了惯性的保持；Adam还记录了二阶矩，过往梯度的平方和当前梯度的平方的平均，这体现了环境感知；Adam也能像RMSProp那样自适应调整学习率。Adam有三个参数需要调节，学习率，还有$\beta1和\beta2$，其中$\beta1$一般设置为0.9，$\beta2$一般设置为0.999。注意Adam中对指数加权平均的偏置作了修正。

![1552907653353](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552907653353.png)

参考：

NG的DeepLearning.AI

葫芦书P161页关于优化算法的介绍

[深度学习优化算法总结](https://blog.csdn.net/qq_28031525/article/details/79535942)

## 网络感受野大小计算方式

![1564390680747](.\imgs\深度学习\1564390680747.png)

其中L(k-1)为第k-1层的感受野大小，f(k)为第k层的卷积核大小，s(i)为第i层的stride大小。下图为一个图片经过不同参数的卷积层输出特征图，感受野大小的计算。其中dilation参数为1的时候代表普通卷积，当d大于1代表空洞卷积了。当卷积核为空洞卷积的时候，为了计算感受野的大小，我们可以先计算空洞卷积核实际的计算大小new_kernel,然后将实际计算的卷积核大小带入公式算输出特征图大小和感受野大小。

## 卷积输出尺度计算

out=floor((in+2*padding-kernel)/stride)+1（floor向下取整，ceil向上取整）

当卷积为空洞卷积的时候，空洞卷积会放大卷积核的感受野，从而减小输出特征图大小。对含有空洞卷积的输出大小有两种计算思路1.空洞卷积相当于对kernel填充0，每个像素间填充ratio-1个0，故最后实际的卷积大小为new_kernel=kernel+(kernel-1)*(ratio-1).将这个new_kernel的尺寸带入到上面的公式即可算出输出特征图的大小。2.直接用以下公式算，其实跟第一种方法是一样的。![img](file:///C:/Users/49149/AppData/Local/Temp/enhtmlclip/Image.png)![img](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAogAAAAuCAYAAACrk+hgAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABQwSURBVHhe7Z09jhy3EsffUXwHXcQncLiJ5dSZhPdiYeHEsFIDzgQsIGHvYAgT6Aq2FwJ8g4cHJ/1YZLO7vsn+mp2ZreAHbTeb7GLVv8iantHMv/77v3+GIAiCIAiCIKhEgRgEQRAEQRAQokAMgiAIgiAICFEgBkEQBEEQBIQoEIMgCIIgCAJCFIhBEARBEAQBIQrEIAiCIAiCgBAFYhAEQRAEQUC4uALx68MPw6v7L2pbF08Pw+tXr4bXD3/r7Qqn+2XXnwuw61WaS2b0CT737qT3O46/hw/fW/flbV+Gd69+GD484WuWUMZ79f3D8FVtl2zWzmqehk9vfhk+q23bceeV9X4/nPC50/3u+sg2MC32gPW6Ose0ORp5fmR+lLGZHZsYNb7Y3o5+p1+GNx+f5PmK8OnWfN2ZMb55jgvWgC5uLT844Lu9fZYAW3t89vn9na+93ejbI8Dubt+O2sgs8aHX76B4nINDC8Q1G/bmTd7YODxaAtps0xpAcKaoeDF2HvJiZvhBtl1igbjSpj8fh+/+/e3wTebH4bc/axsUhrAYnoZP7x+Hzx/fDndvHoc/eP+NuPMSG33iqA3QsOHp8cfRN4mfHocn5ZpFizRHm6Ob5yvzw825UeMHFIi6nV+G/0ya+3b4z2ftGqV/Kgzv7tKLlfTvz6fT8PPdXfoXtWcgD/h9L6xArDRisoqbyI9ZH5o21u5Zk62qnT0aAc0tebG8RXd9e8Qi33p6M/cBhNH/mHgcz+0ViCtoCeg5bPLvuXID3IKXOGrb+TecdpwaNv31OLwRi9vX4bef5sUgJyxL1j+gMEwb8VGvmt15acXTAZg2fH5P/JH986u8bvcC0eWYAnF/LDtBc3jjh2JA25Cs/qUwzIUiOV/QY/GCCsQDOGt+5EIF9FCKxO4XDw1+/zUVIsk2bY2baMQjr4XvT2qbzvG626dAZDmYY/B++J1fZ/b346E9de2Kx8G0C8TxlXp9fIodzR0/HbM+Wl+LkmgP2Zmln/7koI6JHQ73185r/TJjQhe7H5JQx/M1wBvmsZY8f3FPnkCW2Mr5qR8RqtMG80zHJ3RvOkdP3FbbmPgPKWHUMaF9toe0QZLVNrHosnlkikY87WBt8H7T2GqByCALg/IEEfWHe7474Xmi+3FtsUVF6AD7Qeiyjot9wzUDdtyneBgxdvID0DdAXsiU42+UhXNaG9h5E3OOjTzPGJo0fU61OFHni/uxOGWwXhPTfaFfuv6Daa9hJysq8nEqBL57/Eqv0/orTxDJxpPnwnSfGfN11Ez1MZnLOAc+D1vnDc2NfWub6VvtvAeLx3xPLz9wW4X6ybP17PmR8QrExBrfJfyCxNBsBtbDt8Onv9h5Ix7EnxM0z831E48p/C7Hxr6layvLBcNnvLDPx5rvPZ87bd7b8pdbIOZFASdSCVYVBxc1P9aTxqcGT79HWXDmgPJjQBMwtZsHqoipzlP2XzMPCDg8VSIsePvRv6c2x3KOx6OM4bWl43Hxn9rFJqL5udVWfD75mYwJ9mBd8eOC5gNid77H3M/Xjrxe0FEg8oWioH8GkepKs4deW+3O80D6JH7gOSliBWjz9OJR2qz8AHQ94lfVdbNir7RHvLkLuuao5UBP2wz2ecZb3AGtHc5h27Dt+W+kV9FftxNrrG4Ov6u6c+ZpfQYRbBBxBGbNZN2Sa6AN+58e5+vZcYm1p7miKawJfpxpxUSgryWUea56O8yBtrdsPWt+TNQxtTagPU+NVkGizzUBL07E08NWPGwbbV3N12i25H7oHOnH9a8dK3qDp3n1BVp9sofPTbh6ted6nQUid14CO5sHjB+bQnLgfcgx2AMLDoE7XFs0y0I1ncvj2MLbYx5b8e9pzXGeU2YSq9eW/lY3YAS0W6I323gyoOO6cTL4Rqf5AGIzn6NxdbUzXS8TVC3mEyJh85Mc5W0FA64jmk/Fdjz/cq2MLZ6HmJMaO22e/Bw+LrZY+QFosYB+ebP7XN/yQuc6NsD61nylflaub45aDrTaLJ+P7TgnNJR2sJXOC92b2y3modtZC8S6EeFz+DrfBzrS3srsG9Ge9UD91vfCx9NcsV2MyzXWiolCXiPSWLpNALeLAj6iPm3bes78mGkViGA3n2f9+MGI8tCiWZBATMRcy7sp0sZWPOxY2LqakX6X4+Fxqi0ErC9Db6UY/JKfAONCcVmByOKRH0igWEzQhw1RICJ4H3KsCpOjL5pUGLaAtOM18zj/E0RIDLaJTmL12tLf6gaMgHZL9GYbT1R07I2HUH0AdqPk9uIk+8vFg+A9QVxYHAJcR1i/WY/ItvlaGVs8DzEnNXbaPJ14pONsj5EfgBoL7S0z47M5whcOfXPU89xrs30+XoNzQkNpB1vpvNC9ud1iHsYclLeU1c3I9YGOtLdS9QD/sjGRbjXs2HqaA9ulzgStmDhkHYGehe3cLoQ617at58yPmTUFYptVBSKsnY39TY+HHYsen0i/y/HwOPC3my+G3rJPiK/5xwdGXL3a8biNt5jZMTh7Cg44JgWfBNR1lg4PODnO928tiMqiCf0cO7gQhTBXzGMr+oJTUeY4npvtxsdeWzoWGxcHks5qt9p4ouJj+Jv5WEH6AOzWEwxwtZMp8zb1YxSIZXFYVhwCVEf43pr/52Mtr+hx9XfxI3/aJ32vnUPHjfwALD1m36AnW/ipF0bklEfXHL1Yam2+z+dzmpZHtHWA2MqO+XhifGsO7CnT9J8S8DWA5wMDsE+Jo9AD1sroK+s+dmwdzaXjrPPWuqr5fAlgu+jP7ULnjXu1bD1rfky0CkSYp6Nng1ZBAnPltkKBoz09FIh42Bru8Ym1xtd+uR3leTl2fGLpjRf21gMDV692PK6zQATyggcLdIEEclw4cltyCvwnBxrQEqzatxVsgAdcCIDZMweD3qtS7c0JTtroQoVtk8JcPo+tSOED/hyLAFEb6e+05Th6C0m5r75BWG1wP3tzINrJzPevSU2o9vL4J2o8mtoBSH82Z7VALItw/qoBhHyaI+GaI7phdsAH+ed2FCvQN1yL5jGPC/6Ea+s8WIyna2qbHQ8vPwBdj4W86VXfKJsfIHPKx56jlwON/HB9XiB+cDSHNwGqV+Q3nlciz5y8yhtS9atWHAJeXhqYuc70Mc558g/3AZq/HVtfc1q89FiNoHvawD1wP35/3IbbNe102po4b35oa5KiEfBhl88K5YUwG1fYq2jOe+fFjccIifWsTc8nNOdGqv/x3pLOwbV4HJLjCXIPz2fjk/2C8cDA6++0aQViXzyOpV0g3gLKophFYiR0oLBS+PuiLE5wb3XDe36WLfrPSEd+eBtgD1fji7Oi6HkR6/pHLPbn8vJjq7YMlLXee/p1dWzdy8z+B8XjYF5GgSiKiBKsWCSXwYuG3rb9KK9GcZLlhfksxelyrmYj7siPKBCPYOumsba/zKNgG5eWH1vt0QHdKE8Ab4mDCsRj4nE8Zy8Qs6PQ413CgQ7MBcyZ7nW7wIZkLRBe247kYgbH8jKfHgLXVBS18oPk7YLcweNGgcgpBV71T3/BtrYfAp4aX+gLK4/n2j9aXFR+HBRbsPXmX1Tg/WWJD71+V5prwMt4ghgEQRAEQRB0EwViEARBEARBQIgCMQiCIAiCICBEgRgEQRAEQRAQokAMgiAIgiAICFEgBkEQBEEQBITrLBDH/1Lu/5f7/u9ser6vI6FfV1FtwF99cPavFVC+NLmrzSL3afn3UmJ1Gn5e8HvZS/Fs19qKDvb8Gp9n/FqVhPpdYGou4/vt/dVJ49i7fu1E+V7BxfaOuVH6aXF+Gj69sX6hYgT8h+fCj5+ZI9eyW8sPAcRy76/u6f7KFdBe58/nbWXn/Rw45GuHjojHhXNogahuCHuwSlAlibU+2uZ8Dnz/2PYeR9no9Ht6bQ4rC0TLN5tiZf5UUioM72AxTP++P+VfBrhL/4r+G/Fs19rKYrX/BqjHsPz4PPjG/hnBbZrsLxAryzaFQsvG0r5/gWjZOf8smvmbueKFV9mc33w8DZ/ePw6fP74d7rQXLrkfuy/484IKxMIxa9l58wP99Jn5u7gr5jmtSfpPt61b7/xc7tqX4efzlrxY3qK7Vfu5jzvHhs8By+9HxOOSuc4CsQsuKDt51wV9O/59j1lUPTx7jvXRvgXiH7ChigIPNup5QdB+ND8XhrlQnM/tyfP5t2Jpqv7of1nIzloguhxRIB6BYWf+PWX4jdzqX9ZeEQViIes46VH/GTNjni+oQNwf2866XuQicacCcRorFyxWsbI0B3pyuW3n4p/PO1x3y/xgrTV9PvfWY8cO57f822vrZdIuEMcnQNpjV+7E6Zj10fqqQD9FZDBuEXMRdhlPCxIED9+zXJPFQs7PbXX81w8Pc9+DF1i4n7SHbxBGEjvxoP5J4HlAAqeEwfcmYxublN0G91JiMN4H/jbvldFj1dJOT6z0ApEBC8S00CtPEKdXz2Bnmvv4KjeDFh6uLa5xHmvcbrZhH/D5QVs698HyLbZzZL5na2PYv0AUuTf5DmtVy2VAX4wtn7fynPhG2TxoPGa9w7hEcyIXnE1jbF9WICpPEPnGA3PR1ilyvuYYnYs2xymfT4r2Wpqb7lPgObBGNwCNB/Kvlx/MFnEN7pugNrXt3LNAnGgUKzlmil59Grls6ScD66H8aIMeD8XfAMlzQ1ejv0ofLX/42PQaYg+bS9NnqwtEZ2y1QKzcYoGYkwkHpQSsJgB3Ij9eLmwYvyxa0LeMNQqMiAeu087h5OTX2MlbhFav7U/y+sSJsOCxvCdC1Q43HuV6Ho/J/+PmOI3HFwg4tmJltMH4ebxxA4Gx5rjV6zR/tmJla6cnVj0FIjwRkMmaFkYRv2Lr7CtpK7123nSJ/8fj6huvbUJbxOsGV/via5g+pA9b2t63QMz3R/brMW3502qrUJ/32KjZweOBbc9/I73KWLXsXPcE0fsMItgk9AJMegCbmB94HpPj4rc5XsiPnubydXju/Lie69dNBq0pajtA7NCA+2K/cq0s185zFIi2PjxauWxrFtZP8fSwFQ8zFsUnqq6mazRbuH7pNVz/2jHPccKGAtGMx4srEPmCksCO407kx80gCUA8RQSnh/vh3T2IiicxoAhKCJRfYydvax5H4d9HsdeNh+In7BMzgQvmhuO0TefTq8N39/clbske6mNjHm6sbO3YsSpPAUXBfvd2+PQXHcNf5DnSNjJHmAtsnhP1Wr1fsdVrm8+pMeOLEz7Of8/jZh+S/nYOFNYUiMzvU4Etr9VjKn3RbDN9DrTmqNkBfdh9kF/59bK/NwdgbYFoQzSImXwj7YE+1G+JSR+O35qak+PScdoxkYBPYSzHr1p+IE73rK/QDR+/befyArE8DZ7XI6WAaBWI2RdUH/XjBxX5sZieXNZ8C/ks18xmPMxY9MReyR8xHr6mjCli6eYoY0uByOKhPihK0CI7CkRx3AySQknqFIDU72sqEvOjaSG8pYICbKG25mFx9ieIbjyoaKfrq0+EfygQK8sWsy2NCedPqTg8pY3i3cMXZdEx5uHGytZOT6y8J4jLikNA2gb3LPOBNjw3fK3er9jqtc3n1Jh5m7VYOJkenBworCkQLeS1ekylL/w2OGf5HGjbKO2APuw+yK/8etnfmwNw5gIRNAP/sjHNPhnHb57m4G9nXSks0Q2n9AU9i/5afoxAjNR8UtaUmbadz/IEMetrmT5WF4inXxrvvhjxMGPR4xMlf8R4+BrDdoS+1iB2LBAnXvxbzOwYnDgFIS9IzKlOAltAYOFpVBZU6v86/f1aBFoRFLGtipheYwWdn/fFsR/+fZTEcuNRrp/HY8etWEC7lVBWG9wfYpXbUky+T3+Tt3SA1jz0WFn29sTKKhDzB80XFYcA01q2HW2OqC0vSkY8Sls99trG+wCaD/D9+bEXw4wSC8KeBWKJDV8fpH1KLnttrs8LrfzNfZgdxFZ2zK+X/b05APsXiGCDOkekmWwn0k8+Nu/jxNbTXJ677++lutFQ52usEdk+Ft/pfLLVtqNt57O9xazN06WVyxA3rgV42qk9PZSIeHCNTPT4pJXnZQyc5zk/HZ9krWsaqGwpEK14vLgCEagL+wgJ9JhwuS057CSSuAa24C8ihbKIVSHwxacc1/EKs2hK33L+3QnurYlO9uNicMWxI/p9qM/m+YztXjy4f3CCWItpxUxwp230Z50DTVp/Hs1YGdrpiZVaIOb/UVq+agBjbtoTXHPUzjzn2nb/QOeB9ZZiQRZVr43FOFP9ymNBjjWf47iVdrlYl8Wr7RurvwXyHdgP85o06eWyn+euzwHsW2N9mPtXe5jvUK7kfiiX+HGxl9kwnofCkPoV/lczu47HtAcrn9n54ivDd4k5d5zYupqrx3hcT4+d+uE5gOfq5YeqHWSrN67jg1wY8liyb0FYnB+5SGFjKsWn1JtHZy5r+oGnh9Y7YK7fCjQvaV7pPvHzHOer3COktvA9TJ91+hzmwveVijm2WiD2rq2XSbtADF4MXlJ4bbeNtflfIGLRL4toVxHQxdb+t8pGjawpECMWB3CJ+XHE+qPZWT4reZYvxj4Dy4pqib3fXdF+sANRIAaI8opOX+C8tlvmehaEvCiSApHH7BI3wFtgo0ZWFYiJ3O/lbFbHc3n5ccQL863F0zVwVIH40h6UnL1AzIEbHwkLbly0VwFsOsrbB822m+V6CsS6QeGcoosZbe/fyNb2eymUQrz4Z4FWcoFX+60oEAF4anyF6yZstFVPnOfbgC8sP46I7QtZw0mdscCHWJdCh1eaa1uIJ4hBEARBEAQBIQrEIAiCIAiCgBAFYhAEQRAEQUCIAjEIgiAIgiAgRIEYBEEQBEEQEKJADIIgCIIgCAhRIAZBEARBEASEKBCDIAiCIAgCxD/D/wHi2Bzufj9DxgAAAABJRU5ErkJggg==)上图为mxnet给出的计算公式，在tf框架下用的ceil向上取整，不过一般算按照floor来。

池化层输出大小计算，其实池化层和卷积计算的公式是一样的

![1564390825386](D:\找工作相关\复习总结\imgs\深度学习\1564390825386.png)

## 为什么用卷积层

1)全连接参数太多且易过拟合； 2）卷积的局部连接，共享参数使得参数量大大减少

## 1*1卷积

相当于对每个空间位置的D维向量做了一个线性变换。通常用于增加非线性或者降维，减少参数

## 卷积结果的分布式表示

多对多概念，神经元参与到不同特征表示，特征也由不同神经元组成

## 常见初始化

xavier-uniform初始化

$randn(in,out)*\sqrt{6/(in+out)}$

xavier-normal初始化

$randn(in,out)*\sqrt{2/(in+out)}$

He-uniform初始化

$randn(in,out)*\sqrt{6/in}$

He-normal初始化

$randn(in,out)*\sqrt{2/in}$

### 反卷积、上采样、反池化

这三种都可以实现特征图放大，但是实现的方式略有不同

![è¿éåå¾çæè¿°](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20180127154813206.png)

##  各种normalization的区别？

batch，layer，instance**,**group normalization

### Batch Normalization

BN的提出在于解决深度网络训练过程中中间层数值不稳定导致深度网络难以有效训练的问题。优点：

- 加速模型收敛
- 模型不再依赖精细的参数初始化过程
- 学习率可以适当调大一点
- 适当引入了正则化的作用
- 增强泛化能力

BN的思想是在通过批量数据计算激活层的均值方差来做标准化操作来标准化激活神经元分布，并通过可学习的缩放因子和偏移因子来缓解因为归一化所造成的表征能力。总的来说BN是对每个特征维度对标准化操作，使用移动平均来近似数据集的全局均值与方差，测试时候直接使用移动均值与方差。（这儿再细致说一下，在全连接层BN直接统计每个维度特征的统计值来归一化；在卷积网络中，将每个通道看作一个特征维度，统计批量数据在每个通道上激活的统计值，故每个通道维护单独的一份缩放因子、偏移因子与移动平均）在分类等任务中取得了优异的表现，但是BN有几大缺陷：

- batch size太小会导致性能下降
- 对于像素级生成型任务，BN效果不佳（可能是mini-batch内内容无关的样本在特征维度归一化后会弱化单个样本内的细节特征）
- 训练与推断时候统计量不一致

后面出现了几种BN的改进版，他们都抛弃使用mini-batch数据来计算统计值，获取计算统计值的神经元的角度也各不相同，但本质都是从不同角度计算统计值来做归一化。

### Layer Normalization

Layer normalization的思路是直接计算单个实例所有当前层激活神经元的统计值来做归一化，在fc层就直接计算特征之间的统计信息，而卷积层就计算c个通道所有神经元的统计值；

![img](imgs/深度学习/v2-c31a99d3a690e004494cb536ef2abf11_r.jpg)

![img](imgs/深度学习/v2-528b006a0c238284c4f8d7e34547ae28_r.jpg)



### Instance Normalization

instance normalization只能作用与卷积特征图上，该方法计算单个通道内神经元的统计值来归一化

![img](imgs/深度学习/v2-91d2e47119b5a08984c88a458987eaba_r.jpg)

**instance normalization在图像生成类型的任务上要比BN要效果好**

### Group Normalization

Layer normalization和instance normalization都比较极端，而Group normalization稍微中和了一下两者。通道分组在CNN中较为常见，Group normalization自然就是先对所有通道分组，然后在分组内计算统计值归一化。

![img](imgs/深度学习/v2-52f3d854b082a8f03478b7a4e6f9e371_r.jpg)

**Grouo normalization在batch size比较小或者目标检测/视频分类等应用场景下效果优于BN**

可以看出，所有模型都采取了类似的步骤和过程，将神经元的激活值重整为均值为0方差为1的新数值，最大的不同在于计算统计量的神经元集合S的划分方法上。BN采用了同一个神经元，但是来自于Mini-Batch中不同训练实例导致的不同激活作为统计范围。而为了克服Mini-Batch带来的弊端，后续改进方法抛弃了Mini-Batch的思路，只用当前训练实例引发的激活来划分集合S的统计范围，概括而言，LayerNorm采用同隐层的所有神经元；InstanceNorm采用CNN中卷积层的单个通道作为统计范围，而GroupNorm则折衷两者，采用卷积层的通道分组，在划分为同一个分组的通道内来作为通道范围。

至于各种Normalization的适用场景，可以简洁归纳如下：对于RNN的神经网络结构来说，目前只有LayerNorm是相对有效的；如果是GAN等图片生成或图片内容改写类型的任务，可以优先尝试InstanceNorm；如果使用场景约束BatchSize必须设置很小，无疑此时考虑使用GroupNorm；而其它任务情形应该优先考虑使用BatchNorm。

参考：[深度学习中各种normalization模型](https://zhuanlan.zhihu.com/p/43200897)

# 深度学习计算机视觉

## 分类网络（优缺点分析）

### LeNet-5

支票手写数字识别。网络基本架构为：conv1 (6) -> pool1 -> conv2 (16) -> pool2 -> fc3 (120) -> fc4 (84) -> fc5 (10) -> softmax

### AlexNet

imagenet2012冠军网络。结构类似LeNet-5

特点：（1）使用大尺度卷积核，使用ReLU激活  （2）使用dropout  （3）大量数据增强手段

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-e541fc3b67fa98929202ea06a71f4221_r.jpg)

### VGG-16/19

（1）结构简单，只有3\*3卷积与2\*2池化,重复堆叠相同模块，相同感受野下所需参数更少

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-83251f3f6694c7b17b8edb8ee1fff516_r.jpg)

### GoogLeNet

2014年冠军，提出Inception模块 （1）多尺度并行分支结构 （增加网络宽度，增强网络对尺度的适应性）（2）使用1*1卷积降低参数量 （3）使用全局平均替换全连接层

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-ed72c58f966b064ea9befd972b35de64_r.jpg)

### Inception v2/3/4

v2/v3/v4 在GoogLeNet基础上进一步进一步降低参数量，（1）大卷机核替换为小卷积的叠加（2）卷积分解（3）V3使用了BN （4）V4引入残差设计 (5) 使用到标签平滑（一定程度防止过拟合）

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-5fbd16a55b41541554e731bcf747acc6_r.jpg)

### Xception

Xception是Inception v3的改进版本，改进主要体现在depthwise separable convolution的引入。在Inception模块中并行的分支都通过1\*1的卷积来降维，作者简化Inception模块就得到Fig3的结构，先统一1\*1卷积，然后再将卷积后的结果均分给3\*3的卷积去提特征，后来作者再次提出极致版Inception模块，那就是对输入先统一1\*1组合特征，然后每个1\*1卷积结果后面都跟一个3\*3的卷积去提取特征。这儿作者提到的结构就和深度可分卷积类似了。

![è¿éåå¾çæè¿°](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20170715083604924.jpg)

正常的卷积流程如（a）所示，深度可分卷积的流程分两步：第一步逐特征图卷积（如图b）；第二步，通过N个1\*1卷积组合之前得到的M个特征图生成N个特征图

![è¿éåå¾çæè¿°](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20170715083646403.jpg)

![Xception结构](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20170715083812048.jpg)

最后上图就是Xception最终的网络结构图，Xception作为Inception v3的改进，通过引入depthwise separable convocation在基本不增加模型复杂度的情况下提升模型性能。

### ResNet

旨在解决难以训练很深网络的问题，残差设计有效缓解反向传播由于网络太深导致的梯度消失问题。此外，resnet也可以看作为许多不同深度而共享参数的网络集成。（1）残差连接，容易训练更深网络（2）大量使用BN（3）对于很深的网络，使用瓶颈（bottleneck）结构

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-86fe73bfe4dadcbb6c46d62b197e7f1a_r.jpg)

### preResNet

调整残差模块中各层的顺序，直接将残差分支的结果加到原始输入作为当前残差模块的输出，这使得上下层之间的信息更加流畅。

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-4ed38a866a2360353dfebfd501ebe7e4_hd.jpg)

### ResNeXt

受到Inception模块启发，ResNeXt将残差分支变为多个并行分支，不同于Inception不同大小的分支，ResNeXt所有并行分支都相同，最后输出为所有并行分支之和。（1）沿用ResNet的残差连接（2）残差分支采用多分支并行设计（3）采用1*1卷积降低参数量

![img](imgs/深度学习/20170511185626179.jpg)

### DenseNet

不同于ResNet的残差设计，DenseNet任意两两层之间都有连接，这使得当前层的输入来自于之前所有层的输出，融合了低层和高层的特征信息。DenseNet中卷基层的滤波器数较少，总的来说DenseNet获取与ResNet相同的性能所需的参数更少。

优点：

- 减轻梯度消失
- 加强feature传递，更加高效利用feature
- 一定程度减少参数量，也一定减少过拟合

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-414043d909f1186dedace181dcb9db28_r.jpg)

### SENet

2017年imagenet冠军，SENet使用额外分支来调控每个通道特征图的权重

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-c3168b341433cc045e9a8358266a5e44_r.jpg)

参考：

[计算机视觉四大基本任务](https://zhuanlan.zhihu.com/p/31727402)

### MobileNet

深度可分卷积，计算量降低到接近原来的1/9

![1555753261428](imgs/深度学习/1555753261428.png)

### wide ResNet

关键点：增大卷积输出，增加输出宽度/厚度，同时使得网络不太深

其中k为输出通道缩放因子，WRN-28-10就代表网络一共28层，k为10

![1555753491093](imgs/深度学习/1555753491093.png)

特点：获取与原ResNet接近或者更好性能时所需的参数量更少

## 分割网络

### FCN

FCN乃深度语义的开山鼻祖，（1）全脸阶层换成了卷基层 （2）不同尺度的信息融合FCN-8S,FCN-32S

1/32特征图上采样后与1/16特征图相加，再将加和上采样后与1/8相加来预测输出。

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-26c5fb0e9d78b88e9aedd2580fd318aa_r.jpg)

![1552995307740](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552995307740.png)

### U-Net

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-60790e58a4bd4f695252e7b27c33a6ce_hd.jpg)

这个太熟悉了，编码-解码结构，跳层连接，级联特征

### SegNet

SegNet也是编码-解码结构，但区别在于SegNet没有直接将编码层的特征级联到解码层，而是在编码层池化的时候记录最大像素值的位置，在解码层将反池化的时候将对应像素值恢复到原来记录的位置，其他位置补零，这样一定程度恢复了细节信息。此外，这样的操作所需的计算量更少。

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-4fddb46873e7623cd7c3f105df687e57_hd.jpg)

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-acb6a2a047a58ab8d953ea1c7e08111e_hd.jpg)

### RefineNet

RefineNet网络是个U型的结构，左边是编码层，右边RefinNet block的作用就是融合不同尺度的feature map。

![1553000469655](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553000469655.png)

### PSPNet

**Pyramid Scene Parsing Network（PSPNet）CVPR2017**的文章，这篇文章的出发点是引入更多的上下文信息（context information）来减少误分割。引入多尺度上下文信息的是空间金字塔池化结构，该结构通过对输入的特征图进行不同参数的池化得到不同大小的特征图以得到不同感受野上下文的特征，最后将这些不同感受野的特征resize到一样大级联输入进来的特征图作为输出。这儿就完成了不同尺度上下文信息的融合与浅层与深层特征的融合。从源码来看，作者使用了带空洞卷积的Res101作为backbone，空间金字塔池化后的四个特征图大小分别为1,2,3,6。其中在空间金字塔池化前作者还引入了一个辅助分割损失，就是直接输出分割，辅助后面的分割。可参考pytorch-semantic-segmentation-master中源码

![](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20181108215105126.jpg)

![1552998283983](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1552998283983.png)

### Large Kernel Matters

Improve Semantic Segmentation by Global Convolutional Network

提出一种带有大维度卷积核的编码-解码结构，通过全局卷积网络来提升语义分割效果。

语义分割其实是两个任务：定位与分类。分类需要平移旋转不变性，而定位则对位置信息很敏感。那么GCN结构在这两个任务之间找到平衡。使用大内核使得特征图之间有密集连接，优化分类性能，大内核也提供了很大的语义上下文信息也有助于分割任务。

![1553001658337](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553001658337.png)

### DeepLab系列

**DeepLab v1**很直接，（1）通过带孔卷积实现扩张感受野； （2）加入CRF，利用像素间的关系，相邻的像素或者颜色相近的像素更有可能属于同一个类。

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-e2e9eb714875026ad82df05c8a1828d8_hd.jpg)

**DeepLab v2** 的改进之处在于引入了ASPP（atrous spatial pyramid pooling）空洞金字塔池化模块，该模块通过并行的四个带孔卷积捕捉不同尺度的感受野，最后级联起来起到融合不同感受野（感知上下文信息）。此外为了避免池化造成的尺度损失，v2通过空洞卷积来增大感受野。同样采样CRF增强模型捕捉细节的能力。

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-9ab753384aa2e6ea6fd991d9eb0d4e36_hd.jpg)

**DeepLab v3**

（1）改进了ASPP模块：加入了BN层，加入了全局池化，加强全局特征

在旧的ASPP模块中，本来以为只要空洞卷积的扩张率足够大就能获取全局特征信息，但是当扩张率很大的时候，卷积核真正与特征图点乘的位置很少，大多与填充的0做点成，这就导致无法有效捕捉全局特征信息。为了加强全局特征信息，引入全局池化。

（2）引入残差模块  其中改进的Res后面的卷积使用的空洞卷积，也是为了过得更大感受野而不损失特征尺度

（3）丢弃CRF

![preview](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-151368a4580f20f35785a7ae8e99133a_r.jpg)

**DeepLab v3+**

![img](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/v2-132a539931d6d2560341c60e9615e35a_hd.jpg)

DeepLab v3的改进不是很多，可以看出v3+也开始融合浅层的特征了，这就又有点像U型结构了。总来的看，v3+将原来的v3看成编码器，然后上采样和浅层的特征级联作为特征图预测分割结果，利用浅层特征显然是像利用浅层特征更加丰富的空间信息。

此外，编码器部分加入了Xception结构，减少了参数量，提高运行速度。



总结：

- FCN作为深度卷积分割的开山之作，奠定了多尺度特征图融合的基本架构。后期的U-Net，SegNet都是采用了编码解码结构，像PSPNet和DeepLab v3+虽然不能完全是U型，但也通过融合不同尺度的特征图来增强分割性能。
- 为了使得预测结果包含更多的上下文或者不同感受野的特征信息来指导分割的话，PSPNet和DeepLab v3均采用了并行结构获取不同尺度特征图。
- 空洞卷积是个扩张感受野而不损失特征图大小的好东西
- 转置卷积易产生网格效应，简单的上采样resize操作实践中挺好用
- 分割条件允许下，图越大越好
- 分割特定类别，可以考虑引入先验信息+对结果进行形态学处理

参考：

[语义分割综述](https://zhuanlan.zhihu.com/p/37618829)

[PSPNet算法笔记](https://blog.csdn.net/u014380165/article/details/83869175)

## RNN

### LSTM

LSTM通过三个门来更新cell state

![LSTM](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/20170806105635630.png)

遗忘门：

先计算哪些信息被保留哪些被丢弃

![1553085856533](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553085856533.png)

输入门：

决定哪些信息被加入到cell state

![1553085932872](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553085932872.png)

通过遗忘门和输入门来更新cell state

![1553086029152](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553086029152.png)

输出门：

决定cell state中哪些信息被输出

![1553086063072](D:/%E6%89%BE%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%A4%8D%E4%B9%A0%E6%80%BB%E7%BB%93/imgs/%E5%A4%8D%E4%B9%A0/1553086063072.png)

### LSTM为什么能解决梯度消失问题





## 目标检测

### YOLO

### SSD

### RCNN系列

# 传统计算机视觉

# 编程语言

## python深拷贝与浅拷贝的理解

## 智能指针

## 引用与指针的理解

## 







